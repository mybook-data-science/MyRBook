--- 
title: "An Introduction to R for the Field of Data Science"
author: "Moritz Ebach (400104774), Niklas Strolz (400098595), Frederik Miebach (KOWH116385)"
date: "Last update: `r format(Sys.Date(),'%B %d, %Y')`"
site: bookdown::bookdown_site
output: bookdown::gitbook
documentclass: report
bibliography: [book.bib, packages.bib, online.bib]
biblio-style: apalike
link-citations: yes
github-repo: rstudio/bookdown-demo
description: "These are notes gathering our experience to set up R-Studio and use R for data science."
---

# Foreword {-}

Placeholder



<!--chapter:end:index.Rmd-->

---
output:
  pdf_document: default
  html_document: default
---
# (PART) Preface {-}

# About the Authors

Frederik Miebach (LinkedIn: Frederik Miebach) is a business student at Hochschule Fresenius, currently studying in the master's degree of International Business Management. He earned his bachelor's degree in International Business Administration at Hochschule Fresenius in Cologne and is currently working in the field of human resources at the Bayer AG in Leverkusen.

Niklas Strolz (LinkedIn: Niklas Strolz) is also a business student at Hochschule Fresenius, currently studying in the master's degree of International Business Management. He earned his bachelor's degree in International Business Management (German) at Hochschule Fresenius in Cologne and is currently working in the field of business consultancy at Deloitte in Düsseldorf.

Moritz Ebach (LinkedIn: Moritz Ebach) is also a business student at Hochschule Fresenius, currently studying in the master's degree of International Business Management. He earned his bachelor's degree in International Business Management at Hochschule Fresenius in Cologne and just finished an internship in the field of M&A at BELGRAVIA & Co. GmbH in Cologne.

After working with R for the first time for a period of in total four months, the group of students is now working on a student project, which focuses on the design of a book about "R in Data Science". 

<!--chapter:end:01-authors.Rmd-->

# Structure of the book

The preface of the book focuses on a short description of the authors, a short introduction to the book itself, an explanation of what R is and how it can be used, as well as the first steps of a project with R (including the linkage between R and GitHub). The preface is therefore a basic introduction to R and how projects are and can be designed. The first chapter of the book then focuses on source and output files. It is a continuation of the preface with much more detail on how R can be used and how data is imported into R. The first chapter therefore includes topics such as R Markdown files, importing data into R, using R as a calculator and using data structures. Note: The preface and first chapter of the book are fundaments of how to work with R and how to get started. Therefore, it is important to read these two parts of the book very carefully for the first time and follow every step carefully. The second chapter of the book focuses on tidyverse, which is an opinionated collection of R packages designed for data science. All packages share an underlying design philosophy, grammar, and data structures. The final chapter of the book then focuses on how to use R for data science. The knowledge of the first chapter should therefore be utilized for the second chapter of the book. For the chapter of data science or data analysis, we have decided to meke use R basics, in order to analyze various data (e.g. simple functions on vectors, subsetting, functions etc.). 

To sum it up, this book is a reference for working with R as a tool or language for data science. Make sure to make use of the Pareto principle (80/20 rule) when reading it. Not all sections are equally useful or important to the particular book or even books that you intend to write.

<!--chapter:end:02-structureofthebook.Rmd-->

# Introduction

"Data science is the field of study that combines domain expertise, programming skills, and knowledge of math and statistics to extract meaningful insights from data" (DataRobot, 2019).
It is therefore a discipline that allows you to convert raw data into a valuable source of understanding, insight, and knowledge. 

This book is an introduction to R for the field of data science. It was designed in the course of a project study in data science at Hochschule Fresenius in Cologne and is a guide to the language of R with a linkage to the platform GitHub and data science. It is therefore a guide on how to design a book or project with R and afterwards publish it. The goal of the book “An Introduction to R for the Field of Data Science” is therefore designed to help you learn some of the most important tools in R that will enable you to do data science or data analysis. After reading this book, you will have access to a variety of tools to tackle a wide range of data science challenges, using the fundamental parts of R. In order to understand every part of the book, it might be useful to acquire some basic knowledge about R and data science. Therefore, beginners can start with the cheatsheet, which is available at [RStudioCheatsheet](https://www.rstudio.com/resources/cheatsheets/).

<!--chapter:end:03-introduction.Rmd-->


# Explaining R - What is it?

Placeholder


## What is R?
## What is R used for?
## R package
## Communication with R
## Why use R as a language for programming?

<!--chapter:end:04-explainingr.Rmd-->


# The first steps

Placeholder


## Installing the required applications
## Signing up for GitHub
## Creating a new project
## Create a new GitHub repository 
## Link the repository to RStudio 
## Commit and push any changes to GitHub
### Troubleshooting
## Collaboration on GitHub
### Creation of an organization
### Creation of a team
### Member of the team

<!--chapter:end:05-thefirststepsofr.Rmd-->


# (PART) R Basics {-}
# R Markdown files

Placeholder


## General description of R Markdown files
## Getting started with R Markdown files
## Options for R Markdown files
### .rmd structure
### Render options with YAML
## What is a Chunk?
## Improtant options for all chunks
## Latex code {#latex}
## Figures
## Cross-references {#cr}
### Chapters, sections, ... {#cr-chapters}
### Figures
### Tables
### Equations
## Citations
### Writing `.bib` entries

<!--chapter:end:06-rmd_files.Rmd-->


# Import data to R {#import}

Placeholder


## Reading rectangular data
## Read other data types
## Scanning a file

<!--chapter:end:07-import.Rmd-->


# Customize output {#custom-ouptut}

Placeholder


## Multiple built-in output types
## New types provided by packages
## CSS: custom html
## Latex preamble

<!--chapter:end:08-customize_output.Rmd-->


# Data stuctures {#datastructures}

Placeholder


## Atomic vectors
### Types of data 
### Factor vector
## Matrices and arrays
## Lists
## Data frames
### Data frame creation
### Data frame combination
## A word about attributes
## Environments

<!--chapter:end:09-data_structures.Rmd-->


# R as a calculator {#rcalc}

Placeholder


## Usual operators
### Simple operations
## Order of operations
## Number of digits displayed
### Parentheses 
### Exponents 
## Unusual operators
### Special operations
## Usual functions
## Unusual functions

<!--chapter:end:10-calculator.Rmd-->

# (PART) Tidyverse Packages {-}

# What is `tidyverse`? {#tidyverse}

As already mentioned in the preface of the book, many of the functions available in R come in packages. The tidyverse is a collection or bundle of open source R packages introduced by Hadley Wickham (Statistician from New Zealand who is currently Chief Scientist at RStudio) and his team. The fundamental packages of `tidyverse` are dplyr, tidyr, readr, tibble, stringr, ggplot2 and many other packages that provide the functionality to model, transform and visualize data. In general, the packages provided with `tidyverse` make R even better, faster, simpler and just more beautiful. The huge benefits of embracing the `tidyverse` come at the cost needing to learn a sub-dialect of R. This can be daunting for a beginner in R programming that put lots of effort into learning basic R functions. In general, tidyverse packages are intended to make the various processes of statistics and data science more productive through a variety of workflows. It is also the case that the tidyverse is work in progress. 

The next chapters all develop a relevant package, selected from the `tidyverse`. The list of all packages along with a fuller description of the system can be found on [tidyverse.org](https://www.tidyverse.org/).

Let's begin with the installation process of `tidyverse`:

```r
install.packages("tidyverse")
```

<!--chapter:end:11-tidyverse.Rmd-->


# `tibble` {#tibble}

Placeholder


## Creating a tibble
### `as_tibble`
### Manually
### `tribble`

<!--chapter:end:12-tibble.Rmd-->


# `readr`  and `readxl`  {#readr}  

Placeholder


## `readr`
### `read.csv`
### `read_delim`  
## `readxl`

<!--chapter:end:13-readr.Rmd-->


# `magrittr` {#magrittr}

Placeholder


## How to pipe
## Using a placeholder
## Multiple placeholders

<!--chapter:end:14-magrittr.Rmd-->


# extract the characters on either side of the vowel

Placeholder



<!--chapter:end:15-stringr.Rmd-->


# `tidyr` {#tidyr}

Placeholder


## `gather`
## `spread`
## `separate` 
## `unite`

<!--chapter:end:16-tidyr.Rmd-->


# `dplyr` {#dplyr}

Placeholder


## Grammar of data manipulation  
## `select`
### Helper arguments
## `mutate`
## `filter`
## `arrange`
## `summarise`
### Helper functions
## Piping verbs
## `group_by`
## Keys for joins
## Joins
## Operations on data sets

<!--chapter:end:17-dplyr.Rmd-->


# `ggplot2` {#ggplot2}

Placeholder


## Comparison with base `plot`
## Grammar of graphics - Leland Wilkinson
### A graphic = layers of grammatical elements
### Meaningful plots are built around appropriate aesthetic mappings
## Understanding the grammar
### Data and proper data format
### Aesthetics
### Geometries
### Other grammatical elements
### Juggling with `aes`
### Juggling with `geom`
## Aesthetics
### Understanding aesthetics
### Modifying aesthetics
## Geometries
### Scatter plots
### Bar plots
### Line plots

<!--chapter:end:18-ggplot.Rmd-->

---
output:
  word_document: default
  html_document: default
---
# (PART) Use R for Data Science  {-}

After learning about the various functions of R and how they can be used in the previous two chapters, this chapter of the book focuses on how R can be and is used for data science. 

# Introduction to Data Science {#introduction}

In general, Data Science can be described as the overlap of computer science and IT, mathematics and statistics as well as domains and business knowledge. Data Science uses scientific methods, processes, algorithms and systems to extract knowledge. In this case, the focus lies on structured and unstructured data. It uses the above-mentioned methods to solve a variety of problems. It is of great importance to understand a set of data as well as to structure and analyze this data. 

One of the most efficient ways to conduct data science is the use of the programing language R. Due to the fact that many people study R programming during their academic years based on the fact that it is legally free available, R is a well-known tool for data science with many people having at least basic knowledge in the coding language. The huge amount of complex data that is usually processed in data science makes it difficult to structure and conduct data for further analysis. R therefore offers a number of packages that can be used to for reading various forms of data into R, which are explained in detail in the `tidyverse` chapter.

## Data Science = Artificial intelligence - Yes or No?

Artificial Intelligence can generally be seen as intelligence that is demonstrated by machines. Machine learning as part of artificial intelligence enables IT systems to recognize patterns and laws on the basis of existing data and algorithms and to develop solutions.

Additionally, R offers the opportunity to train the algorithm and therefore offers the opportunity to bring in automation for future predictions. R makes machine learning a lot easier and more approachable with the number of packages available especially for machine learning. In conclusion, due to the fact that data science uses statistical learning algorithms such as machine learning, data science can be seen as artificial intelligence. The fact that, broadly speaking, machine learning connects data science and AI, leads to the conclusion that data science and AI can complement each other perfectly. 

## R for Data Data Science

In this chapter of the book, we will discuss data science in the form of conditions, subsets, vectorized functions, plots, loops, functions and many other forms. 

<!--chapter:end:19-introductionDS.Rmd-->


# (PART) Use R for Data Science {-}
# Simple functions and operations on vectors 

Placeholder


## Element by element evaluation
## Recycling rule
## Functions for the whole vector

<!--chapter:end:20-vectorized_functions.Rmd-->


# Subsetting {#subset}

Placeholder


## `[]`
### On a vector
### On a list
### On a matrix
## `[[]]`
## `$`
## Combining subsetting
## Subsetting  with one condition
## Subsetting and assignment
## Using `which()`
## More advanced stuff
### Difference between simplifying and preserving

<!--chapter:end:21-subset.Rmd-->


# Conditions {#conditions}

Placeholder


## `if` statement
## `else` statement
## `else if` statement
## `ifelse` statement
## Logical operators: `&`, `|` and `!`
## Writing and interpreting a condition

<!--chapter:end:22-conditions.Rmd-->


# Functions {#functions}

Placeholder


## Structure of a simple function
### Name of the function
### Arguments
### Commands
### Return of a function
## Multiple arguments and their identification
### Default values

<!--chapter:end:23-functions.Rmd-->


# Loops (avoid them) {#loops}

Placeholder


## Introduction to loops with two examples
## A silly example of loops (Bad R Coding)
## A good example of a loop

<!--chapter:end:24-loops.Rmd-->


# Simple plots {#splots}

Placeholder


## Line plots
## Bar graphs and histograms
### Other plots

<!--chapter:end:25-plots.Rmd-->


# Resampling

Placeholder


## Replication Requirements
## Why Resampling?
## Bootstrapping
### Sample function 
### A bootstrap example
### Built in bootstrapping functions
## Cross-Validation 
### The Validation set Approach
### k-fold Cross-Validation

<!--chapter:end:26-resampling.Rmd-->


# Trees

Placeholder


## Introduction
## Regression trees
## Classification trees
## Avoiding over-fitting of trees with Bagging
## Random Forest

<!--chapter:end:27-Trees.Rmd-->


# Overview {#overview}

Placeholder


## Universal scope
## Statistical learning
## Use of statistical learning
### Prediction
### Inference
## Classification setting
### Bayes classifier
### K-nearest neighbors 

<!--chapter:end:28-overview.Rmd-->


# Linear Regression

Placeholder


## Graphical Analysis
## Simple linear regression
## Multiple linear regression
## Categorical regressors
## Interactions terms
## Polynomials of degree n {#polyn}

<!--chapter:end:29-linear_regression.Rmd-->


# Scoping {#scoping}

Placeholder


## Introduction Part 
## Rule 1: name masking  
## Rule 2: new start
## Rule 3: dynamic lookup
## Functions inside functions
## Examples
## Lexical vs Dynamic Scoping

<!--chapter:end:30-scoping.Rmd-->

---
output:
  pdf_document: default
  html_document: default
---
# Introduction to accuracy assessment


## (Root) Mean square error {#rmse}

This chapter provides an introduction to the task of assessing the accuracy of a fit when the response variable is numeric.  
The most common metric used to assess the quality of a fit is the mean square error (MSE) -- or the root thereof, the **root mean square error** (RMSE). We shall use this latter.   
This metric is simply compiled by taking the root of the average of the squares of the deviations between the predicted values and the observed values.
\[\text{RMSE}(\hat{f}, data) = \sqrt{\frac{1}{n}\sum_{i=1}^n \big(y_i -\hat{f}(X_i)\big)^2}\]

Obviously, the lower the MSE, the most accurate the fit.  
Both \(y_i\) and \(\hat{f}(X_i)\) are vectors. We can write a function to calculate the MSE for any given vector of observed values and predicted values.

```{r}
# a function for calculating the RMSE from two vectors
c.rmse <- function(observed, predicted){
	(observed - predicted)^2 %>%
    mean %>%
    sqrt %>%
    round(3)
}

# c.rmse <- function(observed, predicted){
# 	round(sqrt(mean((observed - predicted)^2)),3) 
# }

```

As a illustration, we can calculate the RMSE error of the different fits of Section \@ref(polyn) to which we had an extra one.

```{r}
require(ISLR)
data("Auto")

# estimate the models
model.pd1 <- lm(mpg ~ horsepower, data = Auto)
model.pd2 <- lm(mpg ~ horsepower + I(horsepower^2), data = Auto)
model.pd5 <- lm(mpg ~ poly(horsepower, 5), data = Auto)  # number in blue is the respective polynom
model.pd9 <- lm(mpg ~ poly(horsepower, 9), data = Auto)




models.rmse <- tibble(
            model = paste0("model.pd",c(1,2,5,9)),
						RMSE= c(
						  c.rmse(Auto$mpg,predict(model.pd1)),
							c.rmse(Auto$mpg,predict(model.pd2)),
							c.rmse(Auto$mpg,predict(model.pd5)),
							c.rmse(Auto$mpg,predict(model.pd9))
							)
					)
models.rmse
```

## Over-fitting

The example above illustrates an important aspect in the context of predictions: the RMSE error calculated on the data that was used to estimate the model decreases with the complexity of the estimated model, for instance as measure by the number of coefficients in the linear model.   

```{r}
# a function for calculating the number of estimated coefficients in lm
n.coef <- function(model){
	model %>%
    coefficients %>%
    length %>%
    {. - 1}
}

length(model.pd5$coefficients) -1

n.coef(model.pd5)

models.rmse$n.coef <- c(n.coef(model.pd1),
                        n.coef(model.pd2),
                        n.coef(model.pd5),
                        n.coef(model.pd9))
```

Now we plot to see the different polynoms with the respective RMSE:

```{r, out.width = "100%", message = FALSE, warning = FALSE, include=TRUE, fig.cap= "RMSE for various numbers of coefficients in the linear model."}
models.rmse %>%
  ggplot(aes(x=n.coef, y= RMSE)) +
  geom_line(color = "dodgerblue") + 
  geom_point(color = "dodgerblue") +
  scale_x_continuous(breaks = c(1,2,5,9) )

# alternatively
# plot(models.rmse$n.coef, models.rmse$RMSE, type="b", col = "dodgerblue")
```

What should become apparent there is always a way to improve the accuracy of the fit when calculating the RMSE using the data that was used to estimate the model. This is a very general conclusion illustrated above by adding terms of a polynomial in the linear model.  

## Train versus test data

In order to avoid over-fitting, one could assess how the model fits the data by calculating the RMSE on data never seen in the estimation of the model. This data is called **test data**.  
Test data may or may not appear naturally in a given context. If it is not, a common strategy is to randomly select a part of the data that will not be used to estimate the model but simply to assess its accuracy. This division is referred to as the train-test split of the data.  
This implies that the RMSE must now be calcultated for two sets of predictions.  
\[\text{RMSE}_\text{train}(\hat{f}, \text{train data}) = \sqrt{\frac{1}{n_{\text{train}}}\sum_{i\in \text{train}} \big(y_i -\hat{f}(X_i)\big)^2}\]
\[\text{RMSE}_\text{test}(\hat{f}, \text{test data}) = \sqrt{\frac{1}{n_{\text{test}}}\sum_{i \in \text{test}} \big(y_i -\hat{f}(X_i)\big)^2}\]

How this works, will be illustrated in the solution to the final task of the project (Section: \@ref(solution_final_task) . This is a good example of how the whole process of calculating the RMSE works.

<!--chapter:end:31-intro_accuracy.Rmd-->


# Final Task

Placeholder


## Data
## Some specifics
### Models and their selection
### NA’s
## Solution to the final task 
## Trial and error 
### First attempt
### Second attempt
## Model used for the solution of the final task (#THE SOLUTION)
### Solution: Multiple linear regression model to cross validation

<!--chapter:end:32-Final_Task.Rmd-->

# (PART) Conclusion {-}


# Conclusion {#conclusion}

This brings us to the end of our book. It is built in the form of a tutorial and contains a variety of hints regarding the use of R in general and the use of R for data science or data analysis.

As mentioned before, the book itself is part of a university project in `Data Science` at Hochschule Fresenius in Cologne. The course itself was designed or intended to learn about the language R and how R can be used for `Data Science`. Please keep in mind that the entire project is a work-in-progress document and that it might contain "simple" errors, due to the fact that this is the first time we are working with R and data science. Since we are "first-time learners" of R and data science, we intended to pass on our knowledge and give the reader a basic understanding of R and how to make use of helpful and life-simplifying tools (e.g. for data science).

It was important for  us to get you started with R and data science, as well as all related machine learning and artificial intelligence tools. 

In our examples, we tried to give a simple understanding of the issue, as well as basic examples (and some advanced examples) for working with and presenting complex models. Our objective was and still is to demonstrate how R can be used to "read" data and convert it into data scientific output. Furthermore, we want to demonstrate how "easy" it can be to use R as a language for data science. When it comes to machine learning, we demonstrated the possible use of a variety of packages that support the use of machine learning with R. 

In case of any ambiguities, the authors are happy to support you and will try to give you valuable advice. 


<!--chapter:end:34-conclusion.Rmd-->

`r if (knitr::is_html_output()) '# References {-}'`

<!--chapter:end:35-references.Rmd-->

